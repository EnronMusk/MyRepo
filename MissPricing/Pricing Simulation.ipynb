{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"try({library(dglm)})\\r\\nWarning message:\\r\\npackage 'dglm' was built under R version 4.1.3 \\r\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"R_HOME\"] = r\"C:\\Program Files\\R\\R-4.1.1\"\n",
    "os.environ[\"PATH\"]   = r\"C:\\Program Files\\R\\R-4.1.1\\bin\\x64\" + \";\" + os.environ[\"PATH\"]\n",
    "\n",
    "import pyper as pr\n",
    "import torch\n",
    "import sklearn as sl\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "\n",
    "r = pr.R(use_pandas = True)\n",
    "#r(\"install.packages('Gammareg')\")\n",
    "r(\"library(Gammareg)\")\n",
    "#r(\"install.packages('dglm')\")\n",
    "r(\"library(dglm)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Simulation\n",
    "We simulate two risk classes. We assume the probability of a claim is 100%. We simulate parameters to be sampled from a Gamma distribution. Parameters are randomly sampled by samples in risk characteristics as follows:\n",
    "\n",
    "$ X_{3} $ indicates a high risk insured.\n",
    "\n",
    "$\\hat{\\theta}_{low} = 1 + \\beta_{1} X_{1} + \\beta_{2} X_{2} $\n",
    "\n",
    "$\\hat{\\theta}_{high} = 2 + 1.25 \\beta_{1} X_{1} + 1.25 \\beta_{2} X_{2} + \\beta_{3} X_{3}$\n",
    "\n",
    "$\\hat{\\alpha}_{low} = 1 + 0.1 \\beta_{1} X_{1} $\n",
    "\n",
    "$\\hat{\\alpha}_{high} = 1 + 0.2 \\beta_{1} X_{1} $\n",
    "\n",
    "**Where samples from each class are defined as:**\n",
    "\n",
    "$\\hat{Y}_{low} \\:$~$\\: Gamma(\\alpha = \\hat{\\alpha}_{low}, \\theta = \\hat{\\theta}_{low}) $\n",
    "\n",
    "$\\hat{Y}_{high} \\:$~$\\: Gamma(\\alpha = \\hat{\\alpha}_{high}, \\theta = \\hat{\\theta}_{high}) $\n",
    "\n",
    "**Our characteristic distribution is as follows:**\n",
    "\n",
    "$X_{1},X_{2} \\:$~$\\: Normal(\\mu = 5, \\sigma = 1) $\n",
    "\n",
    "$\\beta_{1}, \\beta_{2}, \\beta_{3} \\:$~$\\: Normal(\\mu = 5, \\sigma = 0.5) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import SimulateRisk\n",
    "\n",
    "low_risk = SimulateRisk(True, 100)\n",
    "high_risk = SimulateRisk(False, 100)\n",
    "\n",
    "low_risk_samples = low_risk.getData()\n",
    "high_risk_samples = high_risk.getData()\n",
    "\n",
    "total_samples = pd.concat([low_risk_samples, high_risk_samples], ignore_index = True)\n",
    "\n",
    "low_risk_expected = low_risk.getExpected()\n",
    "high_risk_expected = high_risk.getExpected()\n",
    "\n",
    "#Seperate samples from known risk characteristics\n",
    "Y_low = low_risk_samples['Response'].to_frame()\n",
    "X_low = low_risk_samples.drop('Response', axis=1)\n",
    "\n",
    "Y_high = high_risk_samples['Response'].to_frame()\n",
    "X_high = high_risk_samples.drop('Response', axis=1)\n",
    "\n",
    "Y_total = pd.concat([Y_low, Y_high], ignore_index=True)\n",
    "X_total = pd.concat([X_low, X_high], ignore_index=True)\n",
    "Expected_total = pd.concat([low_risk_expected, high_risk_expected], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'try({formula.dispersion = ~ x3})\\r\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Assign our R stuff here\n",
    "r.assign(\"Y\", Y_total['Response'].to_list())\n",
    "r.assign(\"X0\", X_total['x1'].to_list())\n",
    "r.assign(\"X1\", X_total['x1'].to_list())\n",
    "r.assign(\"X2\", X_total['x2'].to_list())\n",
    "r.assign(\"X3\", X_total['x3'].to_list())\n",
    "r.assign(\"data\", total_samples)\n",
    "r(\"X <- cbind(X0, X1, X2)\")\n",
    "r(\"Z <- cbind(X0, X3)\")\n",
    "r(\"formula.mean = Response ~ x1 + x2\")\n",
    "r(\"formula.dispersion = ~ x3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.437574577267581"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = r.get(\"Y\")\n",
    "np.max(u)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the requested diagnostics:\n",
      "mean: 0.05\n",
      "std: 0.05\n",
      "min: 0.00\n",
      "q1%: 0.00\n",
      "q25%: 0.01\n",
      "q75%: 0.01\n",
      "q99%: 0.21\n",
      "max: 0.35\n",
      "\n",
      "Here are the requested diagnostics:\n",
      "mean: 0.14\n",
      "std: 0.09\n",
      "min: 0.00\n",
      "q1%: 0.02\n",
      "q25%: 0.07\n",
      "q75%: 0.07\n",
      "q99%: 0.42\n",
      "max: 0.44\n"
     ]
    }
   ],
   "source": [
    "from functions import sampleDiagnositcs\n",
    "\n",
    "sampleDiagnositcs(Y_low)\n",
    "print(\"\")\n",
    "sampleDiagnositcs(Y_high)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Transform**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luke\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Luke\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "[WinError 2] The system cannot find the file specified\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"C:\\Users\\Luke\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\subprocess.py\", line 503, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\subprocess.py\", line 971, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\subprocess.py\", line 1456, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'try({model = dglm(formula = formula.mean, dformula = formula.dispersion, family = Gamma(link = \"log\"), dlink = \"log\", data = data)})\\r\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import GammaRegressor\n",
    "r(\"library(Gammareg)\")\n",
    "\n",
    "model = GammaRegressor(solver = 'newton-cholesky')\n",
    "model.fit(X = X_total, y = Y_total)\n",
    "\n",
    "model_n = sm.GLM(Y_total, X_total, family = sm.families.Gamma(link=sm.families.links.Log())).fit()\n",
    "#r('a = Gammareg(Y~X1+X2, ~X3, meanlink=\"log\")')\n",
    "r('model = dglm(formula = formula.mean, dformula = formula.dispersion, family = Gamma(link = \"log\"), dlink = \"log\", data = data)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "try({summary(model)})\n",
      "\n",
      "Call: dglm(formula = formula.mean, dformula = formula.dispersion, family = Gamma(link = \"log\"), \n",
      "    dlink = \"log\", data = data)\n",
      "\n",
      "Mean Coefficients:\n",
      "               Estimate  Std. Error    t value     Pr(>|t|)\n",
      "(Intercept) -3.58846377 0.338473810 -10.601895 4.559697e-21\n",
      "x1           0.02647007 0.006312014   4.193601 4.147374e-05\n",
      "x2           0.06652015 0.019436498   3.422435 7.547396e-04\n",
      "(Dispersion Parameters for Gamma family estimated as below )\n",
      "\n",
      "    Scaled Null Deviance: 261.4161 on 199 degrees of freedom\n",
      "Scaled Residual Deviance: 228.0523 on 197 degrees of freedom\n",
      "\n",
      "Dispersion Coefficients:\n",
      "              Estimate Std. Error   z value     Pr(>|z|)\n",
      "(Intercept)  0.4016719  0.1199906  3.347527 8.153604e-04\n",
      "x3          -1.3420138  0.1793066 -7.484462 7.184077e-14\n",
      "(Dispersion parameter for Digamma family taken to be 2 )\n",
      "\n",
      "    Scaled Null Deviance: 292.2948 on 199 degrees of freedom\n",
      "Scaled Residual Deviance: 243.2938 on 198 degrees of freedom\n",
      "\n",
      "Minus Twice the Log-Likelihood: -609.838 \n",
      "Number of Alternating Iterations: 8 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(r('summary(model)'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "try({summary(a)})\n",
      "Error in summary(a) : object 'a' not found\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(r('summary(a)'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>Response</td>     <th>  No. Observations:  </th>  <td>   200</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td>   196</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>          <td>Gamma</td>      <th>  Df Model:          </th>  <td>     3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>          <td>Log</td>       <th>  Scale:             </th> <td> 0.65916</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td>  314.08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Sat, 11 Nov 2023</td> <th>  Deviance:          </th> <td>  163.23</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>18:09:26</td>     <th>  Pearson chi2:      </th>  <td>  129.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>         <td>13</td>        <th>  Pseudo R-squ. (CS):</th>  <td>0.4195</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "   <td></td>     <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x0</th> <td>   -4.2740</td> <td>    0.327</td> <td>  -13.062</td> <td> 0.000</td> <td>   -4.915</td> <td>   -3.633</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th> <td>    0.0296</td> <td>    0.007</td> <td>    4.503</td> <td> 0.000</td> <td>    0.017</td> <td>    0.043</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th> <td>    0.0511</td> <td>    0.020</td> <td>    2.516</td> <td> 0.012</td> <td>    0.011</td> <td>    0.091</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th> <td>    1.0103</td> <td>    0.115</td> <td>    8.762</td> <td> 0.000</td> <td>    0.784</td> <td>    1.236</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}   &     Response     & \\textbf{  No. Observations:  } &      200    \\\\\n",
       "\\textbf{Model:}           &       GLM        & \\textbf{  Df Residuals:      } &      196    \\\\\n",
       "\\textbf{Model Family:}    &      Gamma       & \\textbf{  Df Model:          } &        3    \\\\\n",
       "\\textbf{Link Function:}   &       Log        & \\textbf{  Scale:             } &   0.65916   \\\\\n",
       "\\textbf{Method:}          &       IRLS       & \\textbf{  Log-Likelihood:    } &    314.08   \\\\\n",
       "\\textbf{Date:}            & Sat, 11 Nov 2023 & \\textbf{  Deviance:          } &    163.23   \\\\\n",
       "\\textbf{Time:}            &     18:09:26     & \\textbf{  Pearson chi2:      } &     129.    \\\\\n",
       "\\textbf{No. Iterations:}  &        13        & \\textbf{  Pseudo R-squ. (CS):} &   0.4195    \\\\\n",
       "\\textbf{Covariance Type:} &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "            & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{x0} &      -4.2740  &        0.327     &   -13.062  &         0.000        &       -4.915    &       -3.633     \\\\\n",
       "\\textbf{x1} &       0.0296  &        0.007     &     4.503  &         0.000        &        0.017    &        0.043     \\\\\n",
       "\\textbf{x2} &       0.0511  &        0.020     &     2.516  &         0.012        &        0.011    &        0.091     \\\\\n",
       "\\textbf{x3} &       1.0103  &        0.115     &     8.762  &         0.000        &        0.784    &        1.236     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{Generalized Linear Model Regression Results}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:               Response   No. Observations:                  200\n",
       "Model:                            GLM   Df Residuals:                      196\n",
       "Model Family:                   Gamma   Df Model:                            3\n",
       "Link Function:                    Log   Scale:                         0.65916\n",
       "Method:                          IRLS   Log-Likelihood:                 314.08\n",
       "Date:                Sat, 11 Nov 2023   Deviance:                       163.23\n",
       "Time:                        18:09:26   Pearson chi2:                     129.\n",
       "No. Iterations:                    13   Pseudo R-squ. (CS):             0.4195\n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "x0            -4.2740      0.327    -13.062      0.000      -4.915      -3.633\n",
       "x1             0.0296      0.007      4.503      0.000       0.017       0.043\n",
       "x2             0.0511      0.020      2.516      0.012       0.011       0.091\n",
       "x3             1.0103      0.115      8.762      0.000       0.784       1.236\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_n.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 iterations complete, 0 remaining.\n",
      "100 iterations complete, 0 remaining.\n"
     ]
    }
   ],
   "source": [
    "from functions import SimulatePortfolio\n",
    "\n",
    "portfolio = SimulatePortfolio(iterations = 100, profit = 0.05, size = 1000)\n",
    "portfolio.runSimulation()\n",
    "portfolio.runSimulationAdj()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = portfolio.getHighMeanPercent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = portfolio.getLowMeanPercent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = portfolio.getTotalMeanPercent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03462416415622792"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02801749958258906"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.025603393611053526"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04999512289945326\n",
      "0.04946991511131256\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(portfolio.theoreticalProfit))\n",
    "print(np.mean(portfolio.sampledProfit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0494470438824104\n",
      "0.04770954531293382\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(portfolio.theoreticalProfitAdj))\n",
    "print(np.mean(portfolio.sampledProfitAdj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sharpe ratio for profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8772598147391255"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(portfolio.theoreticalProfitAdj)/np.std(portfolio.theoreticalProfitAdj, ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1383762860448186"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(portfolio.theoreticalProfit)/np.std(portfolio.theoreticalProfit, ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.015930251296430834"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(portfolio.theoreticalProfit, ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.017185463623796395"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(portfolio.theoreticalProfitAdj, ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06482141055024661\n",
      "0.050459381795895944\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(portfolio.theoreticalLowProfitAdj))\n",
    "print(np.mean(portfolio.theoreticalLowProfit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.030067833126809107\n",
      "0.03292064910821297\n"
     ]
    }
   ],
   "source": [
    "print(np.std(portfolio.theoreticalLowProfitAdj, ddof=1))\n",
    "print(np.std(portfolio.theoreticalLowProfit, ddof=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.043247416496321474\n",
      "0.04938018782063788\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(portfolio.theoreticalHighProfitAdj))\n",
    "print(np.mean(portfolio.theoreticalHighProfit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02135925524579955\n",
      "0.01909984834890106\n"
     ]
    }
   ],
   "source": [
    "print(np.std(portfolio.theoreticalHighProfitAdj, ddof=1))\n",
    "print(np.std(portfolio.theoreticalHighProfit, ddof=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.580178364227213"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(portfolio.theoreticalHighProfit, ddof=1)/np.std(portfolio.theoreticalLowProfit, ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011152195721302542"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.017051816216649245"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04569178904702165"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portfolio.highAdj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06179024658171931"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portfolio.lowAdj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we demonstrate the constant pricing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7845989379820157"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portfolio.highAdjOB/np.mean(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7845989379820155"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portfolio.lowAdjOB/np.mean(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.05534925155547421,\n",
       " 0.05346974752193345,\n",
       " 0.04869749506789345,\n",
       " 0.08148168869878392,\n",
       " 0.06384513255418389,\n",
       " 0.07985206874259909,\n",
       " 0.045176247198099095,\n",
       " 0.05237549079824133,\n",
       " 0.04758677388364729,\n",
       " 0.06070812146746152,\n",
       " 0.05949964817084619,\n",
       " 0.05139440808878637,\n",
       " 0.03849256031097481,\n",
       " 0.03670181073133982,\n",
       " 0.047016372264699346,\n",
       " 0.041163074840897984,\n",
       " 0.04078670324681577,\n",
       " 0.05387391206227865,\n",
       " 0.05394839017261366,\n",
       " 0.06345874779230554,\n",
       " 0.06488747145174556,\n",
       " 0.05428481786220585,\n",
       " 0.05259241869398901,\n",
       " 0.06697557353010153,\n",
       " 0.04313248885122245,\n",
       " 0.03114175220709514,\n",
       " 0.0472162476069129,\n",
       " 0.030439744219035725,\n",
       " 0.06619500832953784,\n",
       " 0.049589975457708824,\n",
       " 0.06228713502107175,\n",
       " 0.0261216713900444,\n",
       " 0.04720271890359229,\n",
       " 0.10009995874624567,\n",
       " 0.02308770650313452,\n",
       " 0.03286977006150238,\n",
       " 0.06956924505878348,\n",
       " 0.03980892478751885,\n",
       " 0.03637845217323976,\n",
       " 0.030814907944205938,\n",
       " 0.053660267761240776,\n",
       " 0.05238961121804697,\n",
       " 0.03549833783687695,\n",
       " 0.04906286913075586,\n",
       " 0.07500510597253862,\n",
       " 0.05821439932195538,\n",
       " 0.05946984948397682,\n",
       " 0.06331639773578557,\n",
       " 0.04881386050102787,\n",
       " 0.04600279398340046,\n",
       " 0.022025967521208778,\n",
       " 0.04158790007015112,\n",
       " 0.04049315175605339,\n",
       " 0.03218430638355885,\n",
       " 0.0672358886771971,\n",
       " 0.034338110669107746,\n",
       " 0.062449278929929686,\n",
       " 0.052414285878380706,\n",
       " 0.03583478994923306,\n",
       " 0.05841041185250273,\n",
       " 0.030977609071627832,\n",
       " 0.04534559116208736,\n",
       " 0.06332770412398836,\n",
       " 0.012520954847610177,\n",
       " 0.04451802539223648,\n",
       " 0.044832942692392574,\n",
       " 0.032003346230953245,\n",
       " 0.05903556463835169,\n",
       " 0.06486354104221659,\n",
       " 0.04986968662873181,\n",
       " 0.0966474230934724,\n",
       " 0.06517459130601244,\n",
       " 0.09445678642100763,\n",
       " 0.0503172042130301,\n",
       " 0.0654502527785139,\n",
       " 0.03447674229074271,\n",
       " 0.05671809398226835,\n",
       " 0.04574968204756402,\n",
       " 0.053298370165774656,\n",
       " 0.03472327234028827,\n",
       " 0.06078411784141069,\n",
       " 0.02133052225212806,\n",
       " 0.04883174517970723,\n",
       " 0.0569672097123185,\n",
       " 0.040282571972545145,\n",
       " 0.0477570826769248,\n",
       " 0.05873165016471382,\n",
       " 0.03418430047498344,\n",
       " 0.040864544601381336,\n",
       " 0.03439257938662543,\n",
       " 0.051433310106254404,\n",
       " 0.04347745926332236,\n",
       " 0.02250577893029615,\n",
       " 0.05940092936359176,\n",
       " 0.047176781952872116,\n",
       " 0.037924093068681164,\n",
       " 0.06399244064619036,\n",
       " 0.031110214368576194,\n",
       " 0.042911957797255096,\n",
       " 0.07316439711497957]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portfolio.theoreticalProfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.04312001375541474,\n",
       " 0.05413804984850834,\n",
       " 0.04842584836510033,\n",
       " 0.03745101728617539,\n",
       " 0.05466697356551742,\n",
       " 0.04942095884208919,\n",
       " 0.03664862764473842,\n",
       " 0.0502862520115841,\n",
       " 0.0386140987578133,\n",
       " 0.050190025619943346,\n",
       " 0.03178708495202154,\n",
       " 0.06501430381028905,\n",
       " 0.04894824220657079,\n",
       " 0.05238445002480008,\n",
       " 0.06154562747146619,\n",
       " 0.06657683180164398,\n",
       " 0.02766788061893488,\n",
       " 0.05901197131432734,\n",
       " 0.05120342178603243,\n",
       " 0.06910349592797316,\n",
       " 0.07212629493238387,\n",
       " 0.05535030048186429,\n",
       " 0.06493643099549273,\n",
       " 0.055681434188586176,\n",
       " 0.05282203780365913,\n",
       " 0.05565973191729878,\n",
       " 0.04527566784461656,\n",
       " 0.07364578264833743,\n",
       " 0.03916333398562433,\n",
       " 0.05557061011241038,\n",
       " 0.04835193577021757,\n",
       " 0.060502156837908494,\n",
       " 0.0651279038927638,\n",
       " 0.039760399445391004,\n",
       " 0.0918888331722526,\n",
       " 0.07453504084709961,\n",
       " 0.05964731009168067,\n",
       " 0.047898573842167114,\n",
       " 0.07256899652008131,\n",
       " 0.0629987702582483,\n",
       " 0.0486346993082436,\n",
       " 0.05058756215014226,\n",
       " 0.053186807851553386,\n",
       " 0.05874887325259581,\n",
       " 0.05238227231200854,\n",
       " 0.026310417458732527,\n",
       " 0.042542162905185754,\n",
       " 0.04522833174457297,\n",
       " 0.0566523088655736,\n",
       " 0.04365578137038584,\n",
       " 0.029317414371814787,\n",
       " 0.030257230035566685,\n",
       " 0.0492061167552541,\n",
       " 0.03987077734886013,\n",
       " 0.08145266999411582,\n",
       " 0.056124337795193324,\n",
       " 0.017558787385768215,\n",
       " 0.0737604820138339,\n",
       " 0.07371381157413948,\n",
       " 0.0669342557323328,\n",
       " 0.0509050337187007,\n",
       " 0.016798311808715827,\n",
       " 0.036920852472587584,\n",
       " 0.06279728290234665,\n",
       " 0.07549528761285274,\n",
       " 0.04617700599573005,\n",
       " 0.019526447881553555,\n",
       " 0.06438208662009004,\n",
       " 0.04016077891212522,\n",
       " 0.061412884686360525,\n",
       " 0.015994277550818503,\n",
       " 0.0541671977338275,\n",
       " 0.028980371427635654,\n",
       " 0.030919219395472597,\n",
       " 0.009040994761614352,\n",
       " 0.03375262158515424,\n",
       " 0.062123496457350935,\n",
       " 0.04046251833470138,\n",
       " 0.02177404563013685,\n",
       " 0.04642675977211608,\n",
       " 0.06723314146718229,\n",
       " 0.06708446913709532,\n",
       " 0.025761563206287308,\n",
       " 0.060824698932638976,\n",
       " 0.046069270610843205,\n",
       " 0.032888008656385304,\n",
       " 0.057201979918713786,\n",
       " 0.02791136701725805,\n",
       " 0.07275186593244676,\n",
       " 0.016916215110562405,\n",
       " 0.0679585765041455,\n",
       " 0.008409003699723638,\n",
       " 0.02867847211520358,\n",
       " 0.0829688166321848,\n",
       " 0.0362070363224104,\n",
       " 0.046984011530453285,\n",
       " 0.043562643664150524,\n",
       " 0.06692751587999379,\n",
       " 0.04432116487844573,\n",
       " 0.039985270340122336]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portfolio.theoreticalProfitAdj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7394660415635822"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portfolio.highAdj/portfolio.lowAdj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disparity in profit adj correlates with size of portfolio. As n grows, the risk flips in the sense that high is over priced and low is under priced. For sufficiently low n, high is under priced and low is over priced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio.getSigmaHighList()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio.getSigmaLowList()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'NeuralNetworkBinary' from 'functions' (c:\\Users\\Luke\\MyRepo\\MissPricing\\functions.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Luke\\MyRepo\\MissPricing\\Pricing Simulation.ipynb Cell 49\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Luke/MyRepo/MissPricing/Pricing%20Simulation.ipynb#Y202sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mfunctions\u001b[39;00m \u001b[39mimport\u001b[39;00m NeuralNetworkBinary\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Luke/MyRepo/MissPricing/Pricing%20Simulation.ipynb#Y202sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m train_test_split\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Luke/MyRepo/MissPricing/Pricing%20Simulation.ipynb#Y202sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m resample\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'NeuralNetworkBinary' from 'functions' (c:\\Users\\Luke\\MyRepo\\MissPricing\\functions.py)"
     ]
    }
   ],
   "source": [
    "from functions import NeuralNetworkBinary\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "\n",
    "#We need to first rebalance the transformed dataset. (can't use weights due to loss function not supporting)\n",
    "data_class_1 = transformed_data[transformed_data.overall_positive==1]\n",
    "data_class_0 = transformed_data[transformed_data.overall_positive==0]\n",
    "\n",
    "class_1_resampled = resample(data_class_1, replace=False, n_samples=len(data_class_0), random_state=123)\n",
    "transformed_data = pd.concat([data_class_0, class_1_resampled])\n",
    "\n",
    "#Create data frames for x and y\n",
    "response_var_binary = transformed_data['overall_positive']\n",
    "predictor_var = transformed_data.drop(['overall_positive', 'overall'], axis = 1)\n",
    "\n",
    "#Create test and train datasets\n",
    "X_train_binary, X_test_binary, Y_train_binary, Y_test_binary = train_test_split(predictor_var, response_var_binary, test_size=0.5, random_state=42, stratify=response_var_binary)\n",
    "\n",
    "#Create tensors\n",
    "response_var_binary_t = torch.tensor(Y_train_binary.values, dtype = torch.float32).to(device)\n",
    "predictor_var_t = torch.tensor(X_train_binary.values, dtype = torch.float32).to(device)\n",
    "\n",
    "#Create model\n",
    "n_columns = len(transformed_data.columns)-2\n",
    "\n",
    "model = NeuralNetworkBinary(n_input = n_columns, n_hidden_layer = n_columns, n_output = 1, learning_rate = 0.0075).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert test data to tensors\n",
    "Y_test_binary_t = torch.tensor(Y_test_binary.values, dtype = torch.float32).to(device)\n",
    "X_test_binary_t = torch.tensor(X_test_binary.values, dtype = torch.float32).to(device)\n",
    "\n",
    "model.train(x_train = predictor_var_t, y_train = response_var_binary_t, batch_size=6000, x_test = X_test_binary_t, y_test = Y_test_binary_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Diagnostics ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import accuracy\n",
    "\n",
    "X_test_binary_t = torch.tensor(X_test_binary.values, dtype = torch.float32).to(device)\n",
    "\n",
    "predictions_binary = model.model(X_test_binary_t).detach().cpu().numpy()\n",
    "#Turn probability into prediction\n",
    "predictions_binary = np.where(predictions_binary > 0.5, 1, 0)\n",
    "\n",
    "accuracy(Y_test_binary, predictions_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import confusionMatrix\n",
    "\n",
    "confusionMatrix(Y_test_binary, predictions_binary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
